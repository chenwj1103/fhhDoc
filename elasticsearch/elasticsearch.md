# elasticsearch  

## 由来  
>elasticsearch是为了支持实时的搜索而诞生的。
>最开始有个待业的程序员Shay Banon，想为妻子开发一个搜索菜谱的应用，然后接触到了lucene，直接用lucene构建搜索的时候有很多问题，和大量重复性的工作，所以shay不断地进行抽象，让Java程序嵌入搜索变得更容易，经过一段时间的打磨便诞生了他的第一个开源作品“Compass”，中文即“指南针”的意思。之后，Shay找到了一份面对高性能分布式开发环境的新工作，在工作中他渐渐发现越来越需要一个易用的、高性能、实时、分布式搜索服务，于是他决定重写Compass，将它从一个库打造成了一个独立server，并将其改名为Elasticsearch。

## 是什么
Elasticsearch是一个实时的分布式搜索和分析引擎。它可以帮助你用前所未有的速度去处理大规模数据。
它可以用于全文搜索，结构化搜索以及分析，当然你也可以将这三者进行组合。
Elasticsearch是一个建立在全文搜索引擎 Apache Lucene™ 基础上的搜索引擎，可以说Lucene是当今最先进，最高效的全功能开源搜索引擎框架。
但是Lucene只是一个框架，要充分利用它的功能，需要使用JAVA，并且在程序中集成Lucene。需要很多的学习了解，才能明白它是如何运行的，Lucene确实非常复杂。
Elasticsearch使用Lucene作为内部引擎，但是在使用它做全文搜索时，只需要使用统一开发好的API即可，而不需要了解其背后复杂的Lucene的运行原理。
同时Elasticsearch的横向扩展能力非常强，不需要重启服务，基本上达到了零配置。  
同时他还支持分布式的文件实时存储，每个字段都都被索引并支持搜索、分布式的实时分析搜索引擎、扩展性非常好可以水平扩展上百台服务器，处理PB级别的数据。  
ES与关系型数据库对照：  

    elasticsearch | MongoDB
    ------|----
    索引(indices) | database|
    类型(types) | collection
    文档(document) | document
    字段(Fields) | field

ElasticSearch是构建在极少数的几个概念之上的。ElasticSearch的开发团队希望它能够快速上手，可扩展性强。而且这些核心特性体现在ElasticSearch的各个方面。从架构的角度来看，这些主要特性是：  
开箱即用。安装好ElasticSearch后，所有参数的默认值都自动进行了比较合理的设置，基本不需要额外的调整。包括内置的发现机制(比如Field类型的自动匹配)和自动化参数配置。  
天生集群。ElasticSearch默认工作在集群模式下。节点都将视为集群的一部分，而且在启动的过程中自动连接到集群中。  
自动容错。ElasticSearch通过P2P网络进行通信，这种工作方式消除了单点故障。节点自动连接到集群中的其它机器，自动进行数据交换及以节点之间相互监控。索引分片扩展性强。无论是处理能力和数据容量上都可以通过一种简单的方式实现扩展，即增添新的节点。  
近实时搜索和版本控制。由于ElasticSearch天生支持分布式，所以延迟和不同节点上数据的短暂性不一致无可避免。ElasticSearch通过版本控制(versioning)的机制尽量减少问题的出现。  
## 为什么使用es  
当数据库满足不了我们希望的查询效率的时候就要考虑到使用搜索引擎。
## 分布式的特性
Elasticsearch为分布式而生，而且它的设计隐藏了分布式本身的复杂性。  
Elasticsearch在分布式概念上做了很大程度上的透明化，在elasticsearch中你不需要知道任何关于分布式系统、分片、集群发现或者其他大量的分布式概念。你既可以运行在你的笔记本上，也可以运行在拥有100个节点的集群上，其工作方式是一样的。  
Elasticsearch致力于隐藏分布式系统的复杂性。以下这些操作都是在底层自动完成的：  
将你的文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。  
将分片均匀的分配到各个节点，对索引和搜索做负载均衡。  
冗余每一个分片，防止硬件故障造成的数据丢失。  
将集群中任意一个节点上的请求路由到相应数据所在的节点。  
无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。

## 基本概念
### 近实时
elasticsearch 并不是一个标准的数据库，它不像MongoDB，它侧重于对存储的数据进行搜索。因此要注意到它 不是 实时读写 的，这也就意味着，刚刚存储的数据，并不能马上查询到。当然这里还要区分查询的方式，elasticsearch 也有数据的查询以及搜索，这里的近实时强调的是搜索....
### 集群
在一个分布式系统里面,可以通过多个elasticsearch运行实例组成一个集群,这个集群里面有一个节点叫做主节点(master),elasticsearch是去中心化的,所以这里的主节点是动态选举出来的,不存在单点故障。在同一个子网内，只需要在每个节点上设置相同的集群名,elasticsearch就会自动的把这些集群名相同的节点组成一个集群。节点和节点之间通讯以及节点之间的数据分配和平衡全部由elasticsearch自动管理。
在外部看来elasticsearch就是一个整体。
### 节点
跟集群的概念差不多，elasticsearch 启动时会设置这个节点的名字，一个节点也就是一个elasticsearch 的服务器。默认会自动生成一个名字，这个名字在后续的集群管理中还是很有作用的，因此如果想要手动的管理或者查看一些集群的信息，最好是自定义一下节点的名字。
### 索引
索引是一类文档的集合，所有的操作比如索引（索引数据）、搜索、分析都是基于索引完成的。在一个集群中，可以定义任意数量的索引。一个索引(index)就像是传统关系数据库中的数据库，它是相关文档存储的地方，index的复数是indices 或indexes。
### 类型
类型可以理解成一个索引的逻辑分区，用于标识不同的文档字段信息的集合。但是由于elasticsearch 还是以索引为粗粒度的单位，因此一个索引下的所有的类型，都存放在一个索引下。这也就导致不同类型相同字段名字的字段会存在类型定义冲突的问题。在2.0之前的版本，是可以插入但是不能搜索；在2.0之后的版本直接做了插入检查，禁止字段类型冲突。
### 文档
文档是存储数据信息的基本单元，使用json来表示。
### 分片与备份
在elasticsearch 中，索引会备份成分片，每个分片是独立的lucene索引，可以完成搜索分析存储等工作。

## es的倒排索引
Document:  它是在索引和搜索过程中数据的主要表现形式，或者称“载体”，承载着我们索引和搜索的数据,它由一个或者多个域(Field)组成。
Field:   它是Document的组成部分，由两部分组成，名称(name)和值(value)。
Term:  它是搜索的基本单位，其表现形式为文本中的一个词。
Token:  它是单个Term在所属Field中文本的呈现形式，包含了Term内容、Term类型、Term在文本中的起始及偏移位置。
es把所有信息都写入到一个称为**倒排索引**的数据结构中。这种数据结构把索引中的每个Term与相应的Document映射起来，这与关系型数据库存储数据的方式有很大的不同。读者可以把倒排索引想象成这样的一种数据结构：数据以Term为导向，而不是以Document为导向。下面看看一个简单的倒排索引是什么样的，假定我们的Document只有title域(Field)被编入索引，Document如下：

ElasticSearch Servier (document 1)  
Mastering ElasticSearch (document 2)  
Apache Solr 4 Cookbook (document 3)  

所以索引(以一种直观的形式)展现如下：  

    Term|Count|Docuemnt
    ----|-----|--------
    4|1|\<3\>
    Apache|1|\<3\>
    Cookbook|1|\<3\>
    Elasticsearch|2|\<1\>.\<2\>
    Mastering|1|\<2\>
    Server|1|\<1\>
    Solr|1|\<3\>
每个词都指向它所在的文档号(Document Number/Document ID)。这样的存储方式使得高效的信息检索成为可能，比如基于词的检索(term-based query)。此外，每个词映射着一个数值(Count)，它代表着Term在文档集中出现的频繁程度。  


## 工作原理
当ElasticSearch的节点启动后，它会利用多播(multicast)(或者单播，如果用户更改了配置)寻找集群中的其它节点，并与之建立连接。根据配置文件中的cluster.name（集群名称）去寻找相应的节点。
在集群中，一个节点被选举成主节点(master)。这个节点负责管理集群的状态，并检测其他节点的状态，当群集的拓扑结构改变时把索引分片分派到相应的节点上。 

elasticsearch 是面向文档的，意味着它存储整个对象或文档。elasticsearch不仅存储文档，而且索引 每个文档的内容使之可以被检索。在elasticsearch中，你对文档进行索引、检索、排序和过滤--而不是对行列数据。这是一种完全不同的思考数据的方式，也是elasticsearch能支持复杂全文检索的原因。
elasticsearch添加数据是基于REST风格的API，以JSON格式的文档发送给服务器。在ES内部节点之间的通讯也是基于相关的API，
还可以根据bulk API和UDP bulk API批量添加文档。bulk API采用HTTP协议，UDP bulk API采用非连接的数据包协议。索引数据只会发生在主分片上面。
elasticsearch查询数据使用query DSL（基于JSON），查询包括多种类型：关键词查询、短语、区间、布尔值、模糊、通配符、跨度、地理位置。
查询分为查询分发阶段和结果汇总阶段，查询分发阶段是查询各个分片，结果汇总阶段是把各个分片的结果进行合并排序汇总。

### Elasticsearch 与 Solr 的比较总结  
二者安装都很简单；  
Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;  
Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；  
Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；  
Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。  
Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。    

当单纯的对已有数据进行搜索时，Solr更快。  
当实时建立索引时, Solr会产生io阻塞，查询性能较差, Elasticsearch具有明显的优势。  
随着数据量的增加，Solr的搜索效率会变得更低，而Elasticsearch却没有明显的变化。

### es的优势  
1. 横向可扩展性：只需要增加一台服务器，做一点儿配置，启动一下ES进程就可以并入集群；  
2. 分片机制提供更好的分布性：同一个索引分成多个分片；分而治之的方式来提升处理效率，相信大家都不会陌生；  
3. 高可用：提供复制（replica）机制，一个分片可以设置多个复制，使得某台服务器宕机的情况下，集群仍旧可以照常运行，并会把由于服务器宕机丢失的复制恢复到其它可用节点上;  

### es的不足：  
1. 各节点的一致性问题：其默认的机制是通过多播机制，同步元数据信息，但是在比较繁忙的集群中，可能会由于网络的阻塞，或者节点处理能力达到饱和导致各节点元数据不一致，这样会使集群处于不一致状态。目前并没有一个彻底的解决方案来解决这个问题，但是可以通过将工作节点与元数据节点分开的部署方案来缓解这种情况。  
2. 没有细致的权限管理机制，也就是说，没有像MySQL那样的分各种用户，每个用户又有不同的权限。所以在操作上的限制需要自己开发一个系统来完成；  

### es的成功案例
Github使用Elasticsearch搜索20TB的数据，包括13亿的文件和1300亿行的代码  
Foursquare实时搜索5千万地点信息,Foursquare每天都用Elasticsearch做这样的事  
SoundCloud使用Elasticsearch来为1.8亿用户提供即时精准的音乐搜索服务  
Mozilla公司以火狐著名，它目前使用 WarOnOrange 这个项目来进行单元或功能测试，测试的结果以 json的方式索引到elasticsearch中，开发人员可以非常方便的查找 bug。
Mozilla公司以火狐著名，它目前使用 WarOnOrange 这个项目来进行单元或功能测试，测试的结果以 json的方式索引到elasticsearch中，开发人员可以非常方便的查找 bug。

## 空集群

一个运行中的 Elasticsearch 实例称为一个节点，而集群是由一个或者多个拥有相同cluster.name配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。
当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。
作为用户，我们可以将请求发送到集群中的任何节点，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。

## 查看集群状态
curl -XGET 'localhost:9201/_cluster/health?pretty'
```json
{
  "cluster_name" : "peng",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```
或者curl 'localhost:9201_cat/health?v'  
status字段是我们最关心的。  
status字段指示着。当前集群在总体上是否工作正常它的三种颜色含义如下：   
green  
所有的主分片和副本分片都正常运行。表示所有主分片和3个副本分片都在正常运行。  
yellow  
所有的主分片都正常运行，但不是所有的副本分片都正常运行。  
red  
有主分片没能正常运行。  

## 添加索引
我们往 Elasticsearch 添加数据时需要用到 索引 —— 保存相关数据的地方。 索引实际上是指向一个或者多个物理 分片 的 逻辑命名空间 。
一个 分片 是一个底层的 工作单元 ，它仅保存了 全部数据中的一部分。 在分片内部机制中，我们将详细介绍分片是如何工作的，而现在我们只需知道一个分片是一个 Lucene 的实例，以及它本身就是一个完整的搜索引擎。 我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。
Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。
一个副本分片只是一个主分片的拷贝。 副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。
在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。
一个分片可以是 主 分片或者 副本 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。  
一个副本分片只是一个主分片的拷贝。 副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。
在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。

## 水平扩容
主分片的数目在索引创建时 就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。
副本的数目是可以动态调整的：
curl -XPUT 'localhost:9200/blogs/_settings?pretty' -H 'Content-Type: application/json' -d'
{
   "number\_of\_replicas" : 2
}
'
## 文档元数据

一个文档不仅仅包含它的数据 ，也包含 元数据 —— 有关 文档的信息。 三个必须的元数据元素如下：
_index
文档在哪存放
_type
文档表示的对象类别
_id
文档唯一标识

## 索引文档

通过使用 index API ，文档可以被 索引 —— 存储和使文档可被搜索 。 但是首先，我们要确定文档的位置。正如我们刚刚讨论的，一个文档的 _index 、 _type 和 _id 唯一标识一个文档。 我们可以提供自定义的 _id 值，或者让 index API 自动生成。
在 Elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时（包括删除）， _version 的值会递增。 
如果索引的时候我们不传ID，es会为我们自动生成的 ID 是 URL-safe、 基于 Base64 编码且长度为20个字符的 GUID 字符串。 这些 GUID 字符串由可修改的 FlakeID 模式生成，这种模式允许多个节点并行生成唯一 ID ，且互相之间的冲突概率几乎为零。